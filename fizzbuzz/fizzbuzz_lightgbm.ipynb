{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://joelgrus.com/2016/05/23/fizz-buzz-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_encode(i, num_digits):\n",
    "    return np.array([i >> d & 1 for d in range(num_digits)])\n",
    "\n",
    "def fizz_buzz_encode(i):\n",
    "    if   i % 15 == 0: return 3\n",
    "    elif i % 5  == 0: return 2\n",
    "    elif i % 3  == 0: return 1\n",
    "    else: return 0\n",
    "\n",
    "def fizz_buzz(i, prediction):\n",
    "    return [str(i), \"fizz\", \"buzz\", \"fizzbuzz\"][prediction]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DIGITS = 10\n",
    "NUM_DATA = 10\n",
    "X = np.array([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DATA)])\n",
    "y = np.array([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DATA)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(923, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 0, 1, 1, 0, 0, 0]), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[100:]\n",
    "y_train = y[100:]\n",
    "X_valid = X[:100]\n",
    "y_valid = y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 439, 1: 220, 2: 109, 3: 55}),\n",
       " Counter({0: 54, 1: 26, 2: 13, 3: 7}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "c_train = collections.Counter(list(y_train))\n",
    "c_valid = collections.Counter(list(y_valid))\n",
    "c_train, c_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_samples': 5,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'subsample': 0.9,  # Subsample ratio of the training instance.\n",
    "}\n",
    "\n",
    "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
    "    lgb_train = lgb.Dataset(X_train_df, y_train_df, weight=None)\n",
    "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train,\n",
    "                      # モデルの評価用データを渡す\n",
    "                      valid_sets=lgb_eval,\n",
    "                      # 最大で 1000 ラウンドまで学習する\n",
    "                      num_boost_round=1000,\n",
    "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                      early_stopping_rounds=10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.37055\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.35591\n",
      "[3]\tvalid_0's multi_logloss: 1.34283\n",
      "[4]\tvalid_0's multi_logloss: 1.33057\n",
      "[5]\tvalid_0's multi_logloss: 1.31957\n",
      "[6]\tvalid_0's multi_logloss: 1.30908\n",
      "[7]\tvalid_0's multi_logloss: 1.29964\n",
      "[8]\tvalid_0's multi_logloss: 1.29079\n",
      "[9]\tvalid_0's multi_logloss: 1.28283\n",
      "[10]\tvalid_0's multi_logloss: 1.27523\n",
      "[11]\tvalid_0's multi_logloss: 1.2685\n",
      "[12]\tvalid_0's multi_logloss: 1.2621\n",
      "[13]\tvalid_0's multi_logloss: 1.25639\n",
      "[14]\tvalid_0's multi_logloss: 1.25115\n",
      "[15]\tvalid_0's multi_logloss: 1.24603\n",
      "[16]\tvalid_0's multi_logloss: 1.24165\n",
      "[17]\tvalid_0's multi_logloss: 1.23721\n",
      "[18]\tvalid_0's multi_logloss: 1.23355\n",
      "[19]\tvalid_0's multi_logloss: 1.23021\n",
      "[20]\tvalid_0's multi_logloss: 1.22685\n",
      "[21]\tvalid_0's multi_logloss: 1.22404\n",
      "[22]\tvalid_0's multi_logloss: 1.22145\n",
      "[23]\tvalid_0's multi_logloss: 1.21919\n",
      "[24]\tvalid_0's multi_logloss: 1.21698\n",
      "[25]\tvalid_0's multi_logloss: 1.21496\n",
      "[26]\tvalid_0's multi_logloss: 1.21322\n",
      "[27]\tvalid_0's multi_logloss: 1.21171\n",
      "[28]\tvalid_0's multi_logloss: 1.21006\n",
      "[29]\tvalid_0's multi_logloss: 1.20869\n",
      "[30]\tvalid_0's multi_logloss: 1.2077\n",
      "[31]\tvalid_0's multi_logloss: 1.20649\n",
      "[32]\tvalid_0's multi_logloss: 1.20577\n",
      "[33]\tvalid_0's multi_logloss: 1.20522\n",
      "[34]\tvalid_0's multi_logloss: 1.20468\n",
      "[35]\tvalid_0's multi_logloss: 1.20506\n",
      "[36]\tvalid_0's multi_logloss: 1.20381\n",
      "[37]\tvalid_0's multi_logloss: 1.20224\n",
      "[38]\tvalid_0's multi_logloss: 1.20212\n",
      "[39]\tvalid_0's multi_logloss: 1.20202\n",
      "[40]\tvalid_0's multi_logloss: 1.20192\n",
      "[41]\tvalid_0's multi_logloss: 1.20214\n",
      "[42]\tvalid_0's multi_logloss: 1.20213\n",
      "[43]\tvalid_0's multi_logloss: 1.20133\n",
      "[44]\tvalid_0's multi_logloss: 1.20073\n",
      "[45]\tvalid_0's multi_logloss: 1.20019\n",
      "[46]\tvalid_0's multi_logloss: 1.19957\n",
      "[47]\tvalid_0's multi_logloss: 1.19887\n",
      "[48]\tvalid_0's multi_logloss: 1.19857\n",
      "[49]\tvalid_0's multi_logloss: 1.19758\n",
      "[50]\tvalid_0's multi_logloss: 1.19701\n",
      "[51]\tvalid_0's multi_logloss: 1.1962\n",
      "[52]\tvalid_0's multi_logloss: 1.19567\n",
      "[53]\tvalid_0's multi_logloss: 1.1952\n",
      "[54]\tvalid_0's multi_logloss: 1.19372\n",
      "[55]\tvalid_0's multi_logloss: 1.19341\n",
      "[56]\tvalid_0's multi_logloss: 1.19316\n",
      "[57]\tvalid_0's multi_logloss: 1.19267\n",
      "[58]\tvalid_0's multi_logloss: 1.19242\n",
      "[59]\tvalid_0's multi_logloss: 1.19205\n",
      "[60]\tvalid_0's multi_logloss: 1.19153\n",
      "[61]\tvalid_0's multi_logloss: 1.19164\n",
      "[62]\tvalid_0's multi_logloss: 1.19108\n",
      "[63]\tvalid_0's multi_logloss: 1.19113\n",
      "[64]\tvalid_0's multi_logloss: 1.19113\n",
      "[65]\tvalid_0's multi_logloss: 1.19221\n",
      "[66]\tvalid_0's multi_logloss: 1.19274\n",
      "[67]\tvalid_0's multi_logloss: 1.19361\n",
      "[68]\tvalid_0's multi_logloss: 1.19448\n",
      "[69]\tvalid_0's multi_logloss: 1.19487\n",
      "[70]\tvalid_0's multi_logloss: 1.19527\n",
      "[71]\tvalid_0's multi_logloss: 1.19571\n",
      "[72]\tvalid_0's multi_logloss: 1.19606\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 1.19108\n"
     ]
    }
   ],
   "source": [
    "model = lgbm_train(X_train, X_valid, y_train, y_valid, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = np.arange(1, 101)\n",
    "X_test = np.transpose(binary_encode(numbers, NUM_DIGITS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 2, 1, 0, 0,\n",
       "       1, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 1, 0, 0, 3, 0,\n",
       "       0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 2, 1, 0, 0, 1,\n",
       "       2, 0, 1, 0, 0, 3, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 0, 1, 0, 0, 3, 0, 0,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.array([fizz_buzz_encode(i) for i in range(1, 101)])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53000000000000003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50956917,  0.26906071,  0.1580794 ,  0.06329073],\n",
       "       [ 0.51247212,  0.26489663,  0.15897996,  0.06365129],\n",
       "       [ 0.50956917,  0.26906071,  0.1580794 ,  0.06329073],\n",
       "       [ 0.5096991 ,  0.27289033,  0.15410365,  0.06330692],\n",
       "       [ 0.50891651,  0.27859401,  0.14927976,  0.06320972],\n",
       "       [ 0.50619058,  0.27101189,  0.15992639,  0.06287115],\n",
       "       [ 0.5031266 ,  0.27542447,  0.15895835,  0.06249059],\n",
       "       [ 0.49896627,  0.24614118,  0.1435632 ,  0.11132935],\n",
       "       [ 0.49896627,  0.24614118,  0.1435632 ,  0.11132935],\n",
       "       [ 0.49991784,  0.24661059,  0.14383699,  0.10963458],\n",
       "       [ 0.49760532,  0.24546982,  0.14317163,  0.11375323],\n",
       "       [ 0.49392914,  0.24243511,  0.13895569,  0.12468007],\n",
       "       [ 0.49125292,  0.24653976,  0.1382028 ,  0.12400453],\n",
       "       [ 0.49919348,  0.24501901,  0.14043669,  0.11535082],\n",
       "       [ 0.49880286,  0.25032877,  0.1403268 ,  0.11054157],\n",
       "       [ 0.51247212,  0.26489663,  0.15897996,  0.06365129],\n",
       "       [ 0.50956917,  0.26906071,  0.1580794 ,  0.06329073],\n",
       "       [ 0.51247212,  0.26489663,  0.15897996,  0.06365129],\n",
       "       [ 0.50956917,  0.26906071,  0.1580794 ,  0.06329073],\n",
       "       [ 0.508859  ,  0.27408877,  0.15384966,  0.06320258],\n",
       "       [ 0.51511054,  0.26981377,  0.15109664,  0.06397905],\n",
       "       [ 0.505362  ,  0.27220516,  0.15966461,  0.06276823],\n",
       "       [ 0.50917965,  0.26670719,  0.16087076,  0.0632424 ],\n",
       "       [ 0.49896627,  0.24614118,  0.1435632 ,  0.11132935],\n",
       "       [ 0.49896627,  0.24614118,  0.1435632 ,  0.11132935],\n",
       "       [ 0.49991784,  0.24661059,  0.14383699,  0.10963458],\n",
       "       [ 0.49760532,  0.24546982,  0.14317163,  0.11375323],\n",
       "       [ 0.49320575,  0.24354459,  0.13875218,  0.12449747],\n",
       "       [ 0.49653663,  0.23843585,  0.13968925,  0.12533827],\n",
       "       [ 0.49845461,  0.24613648,  0.14022883,  0.11518009],\n",
       "       [ 0.50425113,  0.24214034,  0.14185955,  0.11174898],\n",
       "       [ 0.51186035,  0.26458041,  0.15998394,  0.0635753 ],\n",
       "       [ 0.5089643 ,  0.26874133,  0.15907877,  0.0632156 ],\n",
       "       [ 0.51186035,  0.26458041,  0.15998394,  0.0635753 ],\n",
       "       [ 0.5089643 ,  0.26874133,  0.15907877,  0.0632156 ],\n",
       "       [ 0.50738546,  0.27165162,  0.15794336,  0.06301956],\n",
       "       [ 0.50193415,  0.27477169,  0.16095168,  0.06234248],\n",
       "       [ 0.50619058,  0.27101189,  0.15992639,  0.06287115],\n",
       "       [ 0.5031266 ,  0.27542447,  0.15895835,  0.06249059],\n",
       "       [ 0.50078685,  0.24339056,  0.14408702,  0.11173556],\n",
       "       [ 0.50078685,  0.24339056,  0.14408702,  0.11173556],\n",
       "       [ 0.4935341 ,  0.23986561,  0.14200025,  0.12460003],\n",
       "       [ 0.4935341 ,  0.23986561,  0.14200025,  0.12460003],\n",
       "       [ 0.49922672,  0.24503532,  0.14044604,  0.11529192],\n",
       "       [ 0.49880025,  0.25032745,  0.14032606,  0.11054624],\n",
       "       [ 0.49554624,  0.24322883,  0.14793544,  0.11328948],\n",
       "       [ 0.49066085,  0.24624262,  0.15092393,  0.11217261],\n",
       "       [ 0.51186035,  0.26458041,  0.15998394,  0.0635753 ],\n",
       "       [ 0.5089643 ,  0.26874133,  0.15907877,  0.0632156 ],\n",
       "       [ 0.51186035,  0.26458041,  0.15998394,  0.0635753 ],\n",
       "       [ 0.5089643 ,  0.26874133,  0.15907877,  0.0632156 ],\n",
       "       [ 0.50655297,  0.27284666,  0.15768422,  0.06291616],\n",
       "       [ 0.50795837,  0.26606748,  0.16288343,  0.06309071],\n",
       "       [ 0.505362  ,  0.27220516,  0.15966461,  0.06276823],\n",
       "       [ 0.50917965,  0.26670719,  0.16087076,  0.0632424 ],\n",
       "       [ 0.50078685,  0.24339056,  0.14408702,  0.11173556],\n",
       "       [ 0.50078685,  0.24339056,  0.14408702,  0.11173556],\n",
       "       [ 0.4935341 ,  0.23986561,  0.14200025,  0.12460003],\n",
       "       [ 0.4935341 ,  0.23986561,  0.14200025,  0.12460003],\n",
       "       [ 0.49848775,  0.24615284,  0.14023815,  0.11512126],\n",
       "       [ 0.50424846,  0.24213905,  0.14185879,  0.11175369],\n",
       "       [ 0.49262675,  0.24325868,  0.15149253,  0.11262204],\n",
       "       [ 0.49366401,  0.23705643,  0.15642038,  0.11285918],\n",
       "       [ 0.51428358,  0.27336348,  0.14803158,  0.06432136],\n",
       "       [ 0.49087943,  0.31074422,  0.13698215,  0.0613942 ],\n",
       "       [ 0.5133615 ,  0.27175772,  0.15002164,  0.06485913],\n",
       "       [ 0.50050943,  0.28998936,  0.14626583,  0.06323538],\n",
       "       [ 0.46659489,  0.30811599,  0.16035231,  0.06493681],\n",
       "       [ 0.4664998 ,  0.31306911,  0.1555954 ,  0.06483569],\n",
       "       [ 0.48485678,  0.3050724 ,  0.14008339,  0.06998743],\n",
       "       [ 0.47591287,  0.29479248,  0.13749934,  0.09179532],\n",
       "       [ 0.50483346,  0.18236688,  0.11875949,  0.19404017],\n",
       "       [ 0.50067116,  0.20389032,  0.11216805,  0.18327047],\n",
       "       [ 0.53153561,  0.2176008 ,  0.12504103,  0.12582257],\n",
       "       [ 0.53814703,  0.24807544,  0.12056397,  0.09321357],\n",
       "       [ 0.47213538,  0.30745376,  0.15515202,  0.06525883],\n",
       "       [ 0.46864278,  0.31257685,  0.15400429,  0.06477608],\n",
       "       [ 0.47276689,  0.30372171,  0.15851319,  0.06499821],\n",
       "       [ 0.468743  ,  0.31427922,  0.15253279,  0.06444499],\n",
       "       [ 0.51585703,  0.27114035,  0.14848448,  0.06451815],\n",
       "       [ 0.53197746,  0.25303748,  0.14845074,  0.06653433],\n",
       "       [ 0.51492287,  0.26954281,  0.15047793,  0.0650564 ],\n",
       "       [ 0.50050943,  0.28998936,  0.14626583,  0.06323538],\n",
       "       [ 0.47463318,  0.30559533,  0.15376604,  0.06600545],\n",
       "       [ 0.46721618,  0.29171521,  0.14690287,  0.09416574],\n",
       "       [ 0.48003224,  0.28874547,  0.13868949,  0.09253281],\n",
       "       [ 0.46560541,  0.25229609,  0.13452134,  0.14757716],\n",
       "       [ 0.51365249,  0.17954824,  0.11648134,  0.19031793],\n",
       "       [ 0.53525803,  0.16027196,  0.115597  ,  0.18887301],\n",
       "       [ 0.54828833,  0.23133535,  0.12433574,  0.09604059],\n",
       "       [ 0.55112172,  0.25921615,  0.119023  ,  0.07063913],\n",
       "       [ 0.47125882,  0.30873954,  0.15486397,  0.06513768],\n",
       "       [ 0.47288335,  0.30635662,  0.15539781,  0.06536222],\n",
       "       [ 0.46582277,  0.31394882,  0.1561849 ,  0.0640435 ],\n",
       "       [ 0.47300779,  0.3080403 ,  0.15392058,  0.06503133],\n",
       "       [ 0.51373302,  0.27307084,  0.14894365,  0.0642525 ],\n",
       "       [ 0.51006502,  0.27363922,  0.15250202,  0.06379374],\n",
       "       [ 0.51278316,  0.27145157,  0.15097921,  0.06478606],\n",
       "       [ 0.49995967,  0.28967084,  0.14720358,  0.06316592],\n",
       "       [ 0.47932856,  0.31679508,  0.13789583,  0.06598053]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13',\n",
       "       '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
       "       '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46',\n",
       "       '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57',\n",
       "       '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68',\n",
       "       '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79',\n",
       "       '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90',\n",
       "       '91', '92', '93', '94', '95', '96', '97', '98', '99', '100'],\n",
       "      dtype='<U3')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.vectorize(fizz_buzz)(numbers, y_pred_max)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.9954545454545454\n",
      "4.027522935779817\n",
      "7.9818181818181815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.999957076632518"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate = []\n",
    "for i in range(4):\n",
    "    rate.append(c_train[0]/c_train[i])\n",
    "    print(rate[i])\n",
    "\n",
    "1.0\n",
    "1.9999964230399152\n",
    "4.0000071539457585\n",
    "7.999957076632518\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(n):\n",
    "    return(rate[n])\n",
    "\n",
    "w = [weights(i) for i in list(y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'learning_rate': 0.05,\n",
    "    'min_child_samples': 5,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'subsample': 0.9,  # Subsample ratio of the training instance.\n",
    "}\n",
    "\n",
    "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
    "    lgb_train = lgb.Dataset(X_train_df, y_train_df, weight=w)\n",
    "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train,\n",
    "                      # モデルの評価用データを渡す\n",
    "                      valid_sets=lgb_eval,\n",
    "                      # 最大で 1000 ラウンドまで学習する\n",
    "                      num_boost_round=1000,\n",
    "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                      early_stopping_rounds=10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.38751\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.38598\n",
      "[3]\tvalid_0's multi_logloss: 1.38706\n",
      "[4]\tvalid_0's multi_logloss: 1.38866\n",
      "[5]\tvalid_0's multi_logloss: 1.38841\n",
      "[6]\tvalid_0's multi_logloss: 1.38913\n",
      "[7]\tvalid_0's multi_logloss: 1.39021\n",
      "[8]\tvalid_0's multi_logloss: 1.39231\n",
      "[9]\tvalid_0's multi_logloss: 1.39463\n",
      "[10]\tvalid_0's multi_logloss: 1.39492\n",
      "[11]\tvalid_0's multi_logloss: 1.39564\n",
      "[12]\tvalid_0's multi_logloss: 1.39674\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's multi_logloss: 1.38598\n"
     ]
    }
   ],
   "source": [
    "model = lgbm_train(X_train, X_valid, y_train, y_valid, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.25661042,  0.24805446,  0.25136374,  0.24397138],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.24867781,  0.25070142,  0.25404601,  0.24657477],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.26064683,  0.24677726,  0.24476693,  0.24780897],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.25263184,  0.24945246,  0.24742034,  0.25049536],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.2512448 ,  0.24984486,  0.25317803,  0.24573231],\n",
       "       [ 0.25661042,  0.24805446,  0.25136374,  0.24397138],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.24867781,  0.25070142,  0.25404601,  0.24657477],\n",
       "       [ 0.25114319,  0.24987877,  0.25321238,  0.24576566],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.24999052,  0.25033407,  0.24829476,  0.25138065],\n",
       "       [ 0.26064683,  0.24677726,  0.24476693,  0.24780897],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.25263184,  0.24945246,  0.24742034,  0.25049536],\n",
       "       [ 0.25512311,  0.24862094,  0.24659559,  0.24966036],\n",
       "       [ 0.25124601,  0.24984446,  0.25317762,  0.24573191],\n",
       "       [ 0.25124601,  0.24984446,  0.25317762,  0.24573191],\n",
       "       [ 0.24418091,  0.25220194,  0.25556656,  0.24805059],\n",
       "       [ 0.24418091,  0.25220194,  0.25556656,  0.24805059],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.25661042,  0.24805446,  0.25136374,  0.24397138],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.24867781,  0.25070142,  0.25404601,  0.24657477],\n",
       "       [ 0.26074952,  0.24674299,  0.24473294,  0.24777455],\n",
       "       [ 0.26074952,  0.24674299,  0.24473294,  0.24777455],\n",
       "       [ 0.25296604,  0.24934092,  0.2473097 ,  0.25038334],\n",
       "       [ 0.25296604,  0.24934092,  0.2473097 ,  0.25038334],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.26064683,  0.24677726,  0.24476693,  0.24780897],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.25263184,  0.24945246,  0.24742034,  0.25049536],\n",
       "       [ 0.25124601,  0.24984446,  0.25317762,  0.24573191],\n",
       "       [ 0.25124601,  0.24984446,  0.25317762,  0.24573191],\n",
       "       [ 0.24418091,  0.25220194,  0.25556656,  0.24805059],\n",
       "       [ 0.24418091,  0.25220194,  0.25556656,  0.24805059],\n",
       "       [ 0.25661042,  0.24805446,  0.25136374,  0.24397138],\n",
       "       [ 0.24541624,  0.25178974,  0.25514885,  0.24764517],\n",
       "       [ 0.24867781,  0.25070142,  0.25404601,  0.24657477],\n",
       "       [ 0.25114319,  0.24987877,  0.25321238,  0.24576566],\n",
       "       [ 0.26074952,  0.24674299,  0.24473294,  0.24777455],\n",
       "       [ 0.26074952,  0.24674299,  0.24473294,  0.24777455],\n",
       "       [ 0.25296604,  0.24934092,  0.2473097 ,  0.25038334],\n",
       "       [ 0.25296604,  0.24934092,  0.2473097 ,  0.25038334],\n",
       "       [ 0.26064683,  0.24677726,  0.24476693,  0.24780897],\n",
       "       [ 0.24933562,  0.25055266,  0.24851157,  0.25160015],\n",
       "       [ 0.25263184,  0.24945246,  0.24742034,  0.25049536],\n",
       "       [ 0.25512311,  0.24862094,  0.24659559,  0.24966036],\n",
       "       [ 0.24698212,  0.25218605,  0.25256826,  0.24826356],\n",
       "       [ 0.2589119 ,  0.25221178,  0.24058744,  0.24828888],\n",
       "       [ 0.24600927,  0.2511927 ,  0.25551238,  0.24728565],\n",
       "       [ 0.2548442 ,  0.24824933,  0.2525184 ,  0.24438807],\n",
       "       [ 0.25586506,  0.24596741,  0.25468274,  0.24348479],\n",
       "       [ 0.24453177,  0.25208003,  0.25385249,  0.24953571],\n",
       "       [ 0.25896978,  0.25579454,  0.23879641,  0.24643928],\n",
       "       [ 0.24880689,  0.2512707 ,  0.24602411,  0.2538983 ],\n",
       "       [ 0.25283326,  0.24675882,  0.24626286,  0.25414505],\n",
       "       [ 0.26182816,  0.24378817,  0.24329819,  0.25108548],\n",
       "       [ 0.25033931,  0.25418986,  0.24383267,  0.25163816],\n",
       "       [ 0.25927627,  0.25115958,  0.24092585,  0.2486383 ],\n",
       "       [ 0.25631198,  0.24776265,  0.25201529,  0.24391008],\n",
       "       [ 0.24322505,  0.25212261,  0.25645008,  0.24820225],\n",
       "       [ 0.25552243,  0.24699944,  0.25431939,  0.24315873],\n",
       "       [ 0.24419494,  0.25312798,  0.25348509,  0.24919199],\n",
       "       [ 0.25143843,  0.25069364,  0.25107358,  0.24679435],\n",
       "       [ 0.25098497,  0.25490952,  0.24316085,  0.25094466],\n",
       "       [ 0.25045385,  0.24971198,  0.2540062 ,  0.24582797],\n",
       "       [ 0.2470003 ,  0.25086254,  0.25517654,  0.24696063],\n",
       "       [ 0.2479478 ,  0.24858439,  0.25739245,  0.24607536],\n",
       "       [ 0.24712482,  0.2512148 ,  0.25298118,  0.24867921],\n",
       "       [ 0.25098885,  0.25854946,  0.24136825,  0.24909344],\n",
       "       [ 0.25143018,  0.25039322,  0.24516495,  0.25301165],\n",
       "       [ 0.25735905,  0.24526414,  0.24477118,  0.25260563],\n",
       "       [ 0.25384253,  0.2464255 ,  0.24593022,  0.25380176],\n",
       "       [ 0.25483569,  0.25266526,  0.24237019,  0.25012887],\n",
       "       [ 0.25134197,  0.25384989,  0.24350654,  0.2513016 ],\n",
       "       [ 0.24838551,  0.25040339,  0.25470135,  0.24650976],\n",
       "       [ 0.24580875,  0.25126184,  0.25557454,  0.24735486],\n",
       "       [ 0.24761225,  0.24962384,  0.25702158,  0.24574233],\n",
       "       [ 0.24678559,  0.25226035,  0.25261623,  0.24833784],\n",
       "       [ 0.25193495,  0.25052735,  0.25090705,  0.24663065],\n",
       "       [ 0.25016986,  0.24877213,  0.25615528,  0.24490273],\n",
       "       [ 0.24388961,  0.25189887,  0.25623069,  0.24798084],\n",
       "       [ 0.24388961,  0.25189887,  0.25623069,  0.24798084],\n",
       "       [ 0.26075223,  0.25066552,  0.24044677,  0.24813548]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 0, 2, 2, 3, 3, 3, 3, 3, 0, 3, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
       "       3, 3, 3, 3, 0, 3, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 3, 0, 3,\n",
       "       0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 3, 0, 0, 2, 0, 2, 0, 0, 2,\n",
       "       0, 3, 3, 0, 1, 0, 0, 2, 0, 2, 0, 1, 2, 2, 2, 2, 1, 3, 0, 0, 0, 1, 2,\n",
       "       2, 2, 2, 0, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23999999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['buzz', 'buzz', 'buzz', 'buzz', '5', 'buzz', 'buzz', 'fizzbuzz',\n",
       "       'fizzbuzz', 'fizzbuzz', 'fizzbuzz', 'fizzbuzz', '13', 'fizzbuzz',\n",
       "       '15', 'buzz', 'buzz', 'buzz', 'buzz', '20', 'buzz', 'buzz', 'buzz',\n",
       "       'fizzbuzz', 'fizzbuzz', 'fizzbuzz', 'fizzbuzz', '28', 'fizzbuzz',\n",
       "       '30', '31', 'buzz', 'buzz', 'buzz', 'buzz', 'buzz', '37', 'buzz',\n",
       "       'buzz', '40', '41', '42', '43', 'fizzbuzz', '45', 'fizzbuzz', '47',\n",
       "       'buzz', 'buzz', 'buzz', 'buzz', '52', 'buzz', 'buzz', 'buzz', '56',\n",
       "       '57', '58', '59', '60', 'fizzbuzz', '62', '63', 'buzz', '65',\n",
       "       'buzz', '67', '68', 'buzz', '70', 'fizzbuzz', 'fizzbuzz', '73',\n",
       "       'fizz', '75', '76', 'buzz', '78', 'buzz', '80', 'fizz', 'buzz',\n",
       "       'buzz', 'buzz', 'buzz', 'fizz', 'fizzbuzz', '88', '89', '90',\n",
       "       'fizz', 'buzz', 'buzz', 'buzz', 'buzz', '96', 'buzz', 'buzz',\n",
       "       'buzz', '100'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.vectorize(fizz_buzz)(numbers, y_pred_max)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "X_r, y_r = make_imbalance(X, y,\n",
    "                      sampling_strategy={0: c_train[3], 1: c_train[3], 2: c_train[3], 3: c_train[3]},\n",
    "                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'learning_rate': 0.05,\n",
    "#     'min_child_samples': 5,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'subsample': 0.9,  # Subsample ratio of the training instance.\n",
    "}\n",
    "\n",
    "def lgbm_train(X_train_df, X_valid_df, y_train_df, y_valid_df, lgbm_params):\n",
    "    lgb_train = lgb.Dataset(X_train_df, y_train_df, weight=None)\n",
    "    lgb_eval = lgb.Dataset(X_valid_df, y_valid_df, reference=lgb_train)\n",
    "\n",
    "    # 上記のパラメータでモデルを学習する\n",
    "    model = lgb.train(lgbm_params, lgb_train,\n",
    "                      # モデルの評価用データを渡す\n",
    "                      valid_sets=lgb_eval,\n",
    "                      # 最大で 1000 ラウンドまで学習する\n",
    "                      num_boost_round=1000,\n",
    "                      # 10 ラウンド経過しても性能が向上しないときは学習を打ち切る\n",
    "                      early_stopping_rounds=10)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 1.3828\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 1.3806\n",
      "[3]\tvalid_0's multi_logloss: 1.37872\n",
      "[4]\tvalid_0's multi_logloss: 1.37686\n",
      "[5]\tvalid_0's multi_logloss: 1.3756\n",
      "[6]\tvalid_0's multi_logloss: 1.37366\n",
      "[7]\tvalid_0's multi_logloss: 1.37291\n",
      "[8]\tvalid_0's multi_logloss: 1.37212\n",
      "[9]\tvalid_0's multi_logloss: 1.37185\n",
      "[10]\tvalid_0's multi_logloss: 1.37192\n",
      "[11]\tvalid_0's multi_logloss: 1.37205\n",
      "[12]\tvalid_0's multi_logloss: 1.37261\n",
      "[13]\tvalid_0's multi_logloss: 1.37276\n",
      "[14]\tvalid_0's multi_logloss: 1.37344\n",
      "[15]\tvalid_0's multi_logloss: 1.37325\n",
      "[16]\tvalid_0's multi_logloss: 1.37475\n",
      "[17]\tvalid_0's multi_logloss: 1.37444\n",
      "[18]\tvalid_0's multi_logloss: 1.37601\n",
      "[19]\tvalid_0's multi_logloss: 1.37562\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 1.37185\n"
     ]
    }
   ],
   "source": [
    "model = lgbm_train(X_r, X_valid, y_r, y_valid, lgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred_max = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26000000000000001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['buzz', 'buzz', 'buzz', 'fizzbuzz', 'fizzbuzz', 'fizzbuzz',\n",
       "       'fizzbuzz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizz',\n",
       "       'fizz', '16', '17', 'buzz', 'buzz', 'fizzbuzz', 'fizzbuzz',\n",
       "       'fizzbuzz', 'fizzbuzz', 'fizz', 'fizz', '26', '27', 'fizz', 'fizz',\n",
       "       'fizz', 'fizz', '32', '33', 'buzz', 'buzz', '36', '37', '38', '39',\n",
       "       '40', '41', 'fizz', 'fizz', '44', '45', 'fizz', 'fizz', 'buzz',\n",
       "       'buzz', 'buzz', 'buzz', 'fizzbuzz', 'fizzbuzz', '54', '55', 'fizz',\n",
       "       'fizz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizz', 'fizzbuzz',\n",
       "       'fizzbuzz', 'buzz', 'buzz', 'fizz', 'fizz', 'fizz', 'fizz',\n",
       "       'fizzbuzz', 'fizzbuzz', 'fizzbuzz', 'fizzbuzz', 'fizz', 'fizz',\n",
       "       'fizz', 'fizz', '80', '81', 'buzz', 'buzz', 'fizz', 'fizz', 'fizz',\n",
       "       'fizz', '88', '89', '90', '91', 'fizz', 'fizz', 'fizz', 'fizz',\n",
       "       '96', '97', 'buzz', 'buzz', '100'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = np.vectorize(fizz_buzz)(numbers, y_pred_max)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
